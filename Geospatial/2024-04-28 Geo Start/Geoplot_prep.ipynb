{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a80757-d479-49a5-8ced-05115b999af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfeacb-eec3-497d-9517-9ccf63b6a828",
   "metadata": {},
   "source": [
    "**Description of fuction bellow**  \n",
    "The funciton no longer assings color. That is done running another function.  \n",
    "***Things to change before running***  \n",
    "freq_list  \n",
    "output_path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff67e02-f099-48ec-8b78-dc1f175ec669",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 147\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aggregated_stats\n\u001b[1;32m    146\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mA404007\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGils Folder\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcomputer vis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject Data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataWareHouse\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mChanged data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mExcelentData\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAllDates\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 147\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_files_in_folder_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Correctly defining frequency list with all values\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Correctly defining frequency list with all values\u001b[39;00m\n\u001b[1;32m    151\u001b[0m freq_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1D\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1W\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1M\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6M\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1Y\u001b[39m\u001b[38;5;124m'\u001b[39m ]\n",
      "Cell \u001b[0;32mIn[3], line 73\u001b[0m, in \u001b[0;36mprocess_files_in_folder_pathlib\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_files_in_folder_pathlib\u001b[39m(folder_path):\n\u001b[1;32m     72\u001b[0m     files_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 73\u001b[0m     folder \u001b[38;5;241m=\u001b[39m \u001b[43mPath\u001b[49m(folder_path)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m folder\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mis_file():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "state_fips_to_full_info = {\n",
    "    '01': ['AL', 'Alabama'],\n",
    "    '02': ['AK', 'Alaska'],\n",
    "    '04': ['AZ', 'Arizona'],\n",
    "    '05': ['AR', 'Arkansas'],\n",
    "    '06': ['CA', 'California'],\n",
    "    '08': ['CO', 'Colorado'],\n",
    "    '09': ['CT', 'Connecticut'],\n",
    "    '10': ['DE', 'Delaware'],\n",
    "    '11': ['DC', 'District of Columbia'],\n",
    "    '12': ['FL', 'Florida'],\n",
    "    '13': ['GA', 'Georgia'],\n",
    "    '15': ['HI', 'Hawaii'],\n",
    "    '16': ['ID', 'Idaho'],\n",
    "    '17': ['IL', 'Illinois'],\n",
    "    '18': ['IN', 'Indiana'],\n",
    "    '19': ['IA', 'Iowa'],\n",
    "    '20': ['KS', 'Kansas'],\n",
    "    '21': ['KY', 'Kentucky'],\n",
    "    '22': ['LA', 'Louisiana'],\n",
    "    '23': ['ME', 'Maine'],\n",
    "    '24': ['MD', 'Maryland'],\n",
    "    '25': ['MA', 'Massachusetts'],\n",
    "    '26': ['MI', 'Michigan'],\n",
    "    '27': ['MN', 'Minnesota'],\n",
    "    '28': ['MS', 'Mississippi'],\n",
    "    '29': ['MO', 'Missouri'],\n",
    "    '30': ['MT', 'Montana'],\n",
    "    '31': ['NE', 'Nebraska'],\n",
    "    '32': ['NV', 'Nevada'],\n",
    "    '33': ['NH', 'New Hampshire'],\n",
    "    '34': ['NJ', 'New Jersey'],\n",
    "    '35': ['NM', 'New Mexico'],\n",
    "    '36': ['NY', 'New York'],\n",
    "    '37': ['NC', 'North Carolina'],\n",
    "    '38': ['ND', 'North Dakota'],\n",
    "    '39': ['OH', 'Ohio'],\n",
    "    '40': ['OK', 'Oklahoma'],\n",
    "    '41': ['OR', 'Oregon'],\n",
    "    '42': ['PA', 'Pennsylvania'],\n",
    "    '44': ['RI', 'Rhode Island'],\n",
    "    '45': ['SC', 'South Carolina'],\n",
    "    '46': ['SD', 'South Dakota'],\n",
    "    '47': ['TN', 'Tennessee'],\n",
    "    '48': ['TX', 'Texas'],\n",
    "    '49': ['UT', 'Utah'],\n",
    "    '50': ['VT', 'Vermont'],\n",
    "    '51': ['VA', 'Virginia'],\n",
    "    '53': ['WA', 'Washington'],\n",
    "    '54': ['WV', 'West Virginia'],\n",
    "    '55': ['WI', 'Wisconsin'],\n",
    "    '56': ['WY', 'Wyoming']\n",
    "}\n",
    "\n",
    "name_to_fips = {info[1]: fips for fips, info in state_fips_to_full_info.items()}\n",
    "\n",
    "# Function to update column names in CSV files within a folder\n",
    "def update_column_names_in_csv(folder_path):\n",
    "    folder = Path(folder_path)\n",
    "    csv_files = folder.glob('*.csv')\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if 'subregion2_name' not in df.columns and 'locality_name' in df.columns:\n",
    "            print(f\"Updating '{csv_file.name}': 'locality_name' -> 'subregion2_name'\")\n",
    "            df.rename(columns={'locality_name': 'subregion2_name'}, inplace=True)\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            \n",
    "# Function to list CSV files in a folder\n",
    "def process_files_in_folder_pathlib(folder_path):\n",
    "    files_list = []\n",
    "    folder = Path(folder_path)\n",
    "    for file in folder.glob('*.csv'):\n",
    "        if file.is_file():\n",
    "            files_list.append(str(file))\n",
    "        else:\n",
    "            print(f\"{file} is a directory, skipping.\\n\")\n",
    "    return files_list\n",
    "\n",
    "# Function to process files and aggregate data\n",
    "def process_files_and_aggregate_data(csv_files, frequency, save_path):\n",
    "    aggregated_stats = pd.DataFrame()  # Initialize an empty DataFrame to collect results\n",
    "    total_files = len(csv_files)\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Processing {file_path}...\")\n",
    "\n",
    "        # Check for required columns in the DataFrame\n",
    "        required_columns = [\n",
    "            'date', 'STATENAME', 'COUNTYNAME', 'DRUNK_DR',\n",
    "            'PERSONS', 'Population', 'FATALS', 'WEATHERNAME', 'LGT_CONDNAME'\n",
    "        ]\n",
    "        missing_columns = set(required_columns) - set(df.columns)\n",
    "        if missing_columns:\n",
    "            print(f\"File '{file_path}' is missing columns: {missing_columns}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure 'date' column is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "        # Map STATENAME to state_fips code before grouping\n",
    "        df['state_fips'] = df['STATENAME'].map(name_to_fips)\n",
    "\n",
    "        # Define grouping columns including both 'STATENAME' and 'state_fips'\n",
    "        group_cols = ['STATENAME', 'state_fips', 'COUNTYNAME', pd.Grouper(key='date', freq=frequency)]\n",
    "\n",
    "        # Filter rows where Population is not NA and greater than 0\n",
    "        df = df[df['Population'].notna() & (df['Population'] > 0)]\n",
    "\n",
    "        # Aggregation dictionary for summing and averaging data\n",
    "        agg_dict = {\n",
    "            'Population': 'first',\n",
    "            'DRUNK_DR': 'sum',\n",
    "            'FATALS': 'sum',\n",
    "            'PERSONS': 'sum'\n",
    "        }\n",
    "\n",
    "        # Perform grouping and aggregation\n",
    "        grouped_df = df.groupby(group_cols).agg(agg_dict).reset_index()\n",
    "\n",
    "        # Calculate incidence rates\n",
    "        for col in agg_dict.keys():\n",
    "            if col != 'Population':\n",
    "                rate_col = f'incidence_rate_{col}'\n",
    "                grouped_df[rate_col] = np.ceil((grouped_df[col] / grouped_df['Population']) * 100000)\n",
    "\n",
    "        # Concatenate grouped data to the aggregated stats DataFrame\n",
    "        aggregated_stats = pd.concat([aggregated_stats, grouped_df], ignore_index=True)\n",
    "\n",
    "    # Save aggregated data if not empty\n",
    "    if not aggregated_stats.empty:\n",
    "        output_file = Path(save_path)\n",
    "        output_file.parent.mkdir(parents=True, exist_ok=True)  # Ensure the directory exists\n",
    "        aggregated_stats.to_csv(output_file, index=False)  # This will overwrite the existing file\n",
    "        print(f\"Aggregated data saved to {output_file}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "    print(f\"{total_files} files processed. Some files may have had NaN values.\")\n",
    "    return aggregated_stats\n",
    "\n",
    "\"\"\"\n",
    "example use\n",
    "\n",
    "folder_path = r\"C:\\Users\\A404007\\Desktop\\Gils Folder\\computer vis\\project Data\\DataWareHouse\\Changed data\\ExcelentData\\AllDates\"\n",
    "csv_files = process_files_in_folder_pathlib(folder_path)\n",
    "\n",
    "# Correctly defining frequency list with all values\n",
    "# Correctly defining frequency list with all values\n",
    "freq_list = ['1D','1W','1M','6M','1Y' ]\n",
    "\n",
    "for freq in freq_list:\n",
    "    output_path = r'C:\\Users\\A404007\\Desktop\\Gils Folder\\computer vis\\project Data\\DataWareHouse\\Changed data\\InterestingCalculations\\ACCIDENTDATA_ALLDATA_{}.csv'.format(freq)\n",
    "    aggregated_data = process_files_and_aggregate_data(csv_files, freq, output_path)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86972a-649c-42d4-9be8-72db3d323d2e",
   "metadata": {},
   "source": [
    "**Description of fuction bellow**  \n",
    "The funciton just assings color. It just adds on color to the csv file so if you had incidence_rate_PERSONS it will now have a column with name color_incidence_rate_PERSONS to help determine what color means what \n",
    "***Things to change before running***  \n",
    "define your color bins, (min,max,color)  \n",
    "freq_list  \n",
    "path  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc2c26d-f21e-4814-8391-33ebf619d941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_mapping(csv_file, attribute, bin_assignment):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    color_mapping = []\n",
    "\n",
    "    for rate in df[attribute]:\n",
    "        color_assigned = False\n",
    "        for bin_range, color in bin_assignment:\n",
    "            if bin_range[0] <= rate < bin_range[1]:\n",
    "                color_mapping.append(color)\n",
    "                color_assigned = True\n",
    "                break\n",
    "        if not color_assigned:\n",
    "            # Assign grey as the default color if attribute value doesn't fall into any bin range\n",
    "            color_mapping.append('#808080')\n",
    "\n",
    "    df['color_' + attribute] = color_mapping\n",
    "\n",
    "    # Override the CSV file with the new color mapping column\n",
    "    df.to_csv(csv_file, index=False)\n",
    "color_bins = [\n",
    "    ((0, 5), '#FFFFCC'),\n",
    "    ((5, 20), '#FFEDA0'),\n",
    "    ((20, 40), '#FED976'),\n",
    "    ((40, 80), '#FEB24C'),  # This range was duplicated, adjusted to follow the sequence\n",
    "    ((80, 160), '#FD8D3C'),\n",
    "    ((160, 320), '#FC4E2A'),\n",
    "    ((320, float('inf')), '#800026')  # You can adjust this color as needed\n",
    "]\n",
    "\"\"\"\n",
    "example use: \n",
    "\n",
    "freq_list = ['1D','1M','1W','1Y','6M']\n",
    "\n",
    "for freq in freq_list:\n",
    "    path = r'C:\\Users\\A404007\\Desktop\\Gils Folder\\computer vis\\project Data\\DataWareHouse\\Changed data\\InterestingCalculations\\ACCIDENTDATA_ALLDATA_{}.csv'.format(freq)\n",
    "    color_mapping(path, 'incidence_rate_PERSONS', color_bins)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5716dd-44c2-4330-a9ab-1dabd07cb997",
   "metadata": {},
   "source": [
    "**Description of function below**  \n",
    "The function will minimize unique colors and determine the minimum and maximum for that unique color, and determine scaling that way. Color size controls how big the color legend size circle is in the plot. Label and spacing determine how much space those circles are to one another.  \n",
    "Note: make sure to change `min_max_list = [f\"{row['Min']} - {row['Max']} Covid Death Range of \\n\\nFrequency: {row['RawSize']}\" for index, row in color_stats_sorted.iterrows()]` the 'Covid Death Range of' for it to make sense to whatever you are plotting.  \n",
    "***Things to change before running***  \n",
    "define your color bins, (min, max, color)  \n",
    "freq_list  \n",
    "path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df01ea5-d6a2-446d-a662-7d7842b91413",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_counties_from_csv(shapefile_gdf, csv_file_path, output_folder, attribute, color_size, labelspacing, title_format=\"Plot for {}\"):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.rename(columns={'state_fips': 'STATEFP', 'subregion2_name': 'NAMELSAD'}, inplace=True)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    grouped = df.groupby('date')\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for date, group in grouped:\n",
    "        df_color = group[attribute].unique()\n",
    "        color_counts = group[attribute].value_counts()\n",
    "        min_count, max_count = color_counts.min(), color_counts.max()\n",
    "        color_to_size = {color: color_size for color in df_color}\n",
    "\n",
    "        data = []\n",
    "        new_attribute = attribute.replace(\"color_\", \"\")\n",
    "\n",
    "        for color in df_color:\n",
    "            color_df = group[group[attribute] == color]\n",
    "            min_value = color_df[new_attribute].min()\n",
    "            max_value = color_df[new_attribute].max()\n",
    "            size = color_to_size[color]\n",
    "            size_raw = color_counts[color]\n",
    "            data.append({'Color': color, 'Min': min_value, 'Max': max_value, 'Size': size, 'RawSize': size_raw})\n",
    "\n",
    "        color_stats = pd.DataFrame(data)\n",
    "        color_stats_sorted = color_stats.sort_values(by='Max', ascending=True)\n",
    "        colors_sorted_list = color_stats_sorted['Color'].tolist()\n",
    "        min_max_list = [f\"{row['Min']} - {row['Max']} Covid Death Range of \\n\\nFrequency: {row['RawSize']}\" for index, row in color_stats_sorted.iterrows()]\n",
    "        min_max_list.insert(0,\"Missing data\")\n",
    "        colors_size_list = color_stats_sorted['Size'].tolist()\n",
    "        colors_size_list.insert(0, color_size)\n",
    "        colors_sorted_list.insert(0, '#808080')\n",
    "\n",
    "        cmap = LinearSegmentedColormap.from_list(\"rate_scale\", colors_sorted_list, N=len(colors_sorted_list))\n",
    "\n",
    "        color_dict = {row['NAMELSAD']: row[attribute] for idx, row in group.iterrows()}\n",
    "        shapefile_gdf['color'] = shapefile_gdf['NAMELSAD'].map(color_dict).fillna('#808080')\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 10))\n",
    "        ax.set_xlim([-130, -66])\n",
    "        ax.set_ylim([24, 50])\n",
    "        shapefile_gdf.plot(ax=ax, color='lightgrey', edgecolor='black', linewidth=0.4)\n",
    "        shapefile_gdf.plot(ax=ax, color=shapefile_gdf['color'], edgecolor='black', linewidth=0.4)\n",
    "\n",
    "        legend_entries = [plt.Line2D([0], [0], marker='o', color=color, label=label, markersize=size, linestyle='')\n",
    "                          for label, color, size in zip(min_max_list, colors_sorted_list, colors_size_list)]\n",
    "        ax.legend(handles=legend_entries, loc='center left', bbox_to_anchor=(-0.10, 0.5),\n",
    "                  handlelength=2, handletextpad=2, labelspacing=labelspacing, borderaxespad=1, fontsize='x-small')\n",
    "\n",
    "        ax.set_title(title_format.format(date.strftime('%Y-%m-%d')))\n",
    "        ax.set_axis_off()\n",
    "        plt.savefig(os.path.join(output_folder, f\"{date.strftime('%Y-%m-%d')}.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(\"All maps have been saved successfully.\")\n",
    "    \n",
    "\"\"\"\n",
    "example use: \n",
    "    # File paths\n",
    "csv_file_path = r\"C:\\Users\\A404007\\Desktop\\Gils Folder\\Data Mining\\projectdata\\ChangedData\\aggregated_stats_4BinsMethod3D.csv\"\n",
    "shp_file_path = r'C:\\Users\\A404007\\Desktop\\Gils Folder\\Data Mining\\projectdata\\GeoShapeData\\tl_2023_us_county\\tl_2023_us_county.shp'\n",
    "output_folder = r'C:\\Users\\A404007\\Desktop\\Gils Folder\\Data Mining\\projectdata\\GeoPlot\\aggregated_stats_4BinsMethod3D_Latest'\n",
    "attribute = 'color_incidence_rate'\n",
    "# Load shapefile into GeoDataFrame\n",
    "shape_df = gpd.read_file(shp_file_path)\n",
    "#shape_df.sort_values(by=['STATEFP', 'NAMELSAD'], ascending=[True, True], inplace=True) #SORTED\n",
    "# Call the function\n",
    "title_format = \"Death Rate to COVID  per 100,000 People:{}\"\n",
    "plot_counties_from_csv(shape_df, csv_file_path, output_folder,attribute, 10, 1.0, title_format)\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
